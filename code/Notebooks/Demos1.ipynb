{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Snippet example *was*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def conv(attr_hs, attr_as, attr_vs, dim, feature_map_size=2, kernel_size=[2, 4], activation=tf.nn.tanh, layer_num=2):\n",
    "    attr_as = tf.reshape(attr_as, [-1, 1, dim])\n",
    "    attr_vs = tf.reshape(attr_vs, [-1, 1, dim])\n",
    "    input_avs = tf.concat([attr_as, attr_vs], 1)\n",
    "    input_shape = input_avs.shape.as_list()\n",
    "    input_layer = tf.reshape(input_avs, [-1, input_shape[1], input_shape[2], 1])\n",
    "    _conv = input_layer\n",
    "    _conv = tf.layers.batch_normalization(_conv, 2)\n",
    "    for i in range(layer_num):\n",
    "        _conv = tf.layers.conv2d(inputs=_conv,\n",
    "                                 filters=feature_map_size,\n",
    "                                 kernel_size=kernel_size,\n",
    "                                 strides=[1, 1],\n",
    "                                 padding=\"same\",\n",
    "                                 activation=activation)\n",
    "    _conv = tf.nn.l2_normalize(_conv, 2)\n",
    "    _shape = _conv.shape.as_list()\n",
    "    _flat = tf.reshape(_conv, [-1, _shape[1] * _shape[2] * _shape[3]])\n",
    "    dense = tf.layers.dense(inputs=_flat, units=dim, activation=activation)\n",
    "    dense = tf.nn.l2_normalize(dense)\n",
    "    score = -tf.reduce_sum(tf.square(attr_hs - dense), 1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Snippet example *is*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "\tdef __init__(self, sizes):\n",
    "\t\tsuper(Conv, self).__init__()\n",
    "\t\tself.norm_channels = sizes[3]\n",
    "\t\tself.in_channels = sizes[1]\n",
    "\t\tself.out_channels = sizes[2]\n",
    "\t\tself.con = nn.Conv2d(self.in_channels,\n",
    "\t\t\t\t\t\t\t self.out_channels,\n",
    "\t\t\t\t\t\t\t kernel_size=[2, 4])\n",
    "\t\tself.con_consequent = \\\n",
    "\t\t\tnn.Conv2d(self.in_channels + 1,\n",
    "\t\t\t\t\t  self.out_channels,\n",
    "\t\t\t\t\t  kernel_size=[2, 4])\n",
    "\t\tself.nrm = nn.BatchNorm2d(self.norm_channels)\n",
    "\t\tself.activ_func_conv = activation()\n",
    "\n",
    "\tdef forward(self, input, conv_times, pad=(2, 1, 1, 0)):\n",
    "\n",
    "\t\tsizes = list(input.shape)\n",
    "\n",
    "\t\tinput = torch.reshape(input, [-1, sizes[3], sizes[2], 1])\n",
    "\t\tres = self.nrm(input)\n",
    "\t\tres = torch.reshape(res, [-1, 1, sizes[2], sizes[3]])\n",
    "\n",
    "\t\tpadded = nn.functional.pad(res, pad)\n",
    "\t\tres = self.con(padded)\n",
    "\t\tres = self.activ_func_conv(res)\n",
    "\n",
    "\t\tfor i in range(conv_times-1):  \n",
    "\t\t\tpadded = nn.functional.pad(res, pad)\n",
    "\t\t\tres = self.con_consequent(padded)\n",
    "\t\t\tres = self.activ_func_conv(res)\n",
    "\n",
    "\t\treturn res  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -6.3395, -11.4238,  -0.1997],\n",
      "        [ -1.0331,  -6.3067,  -4.3848],\n",
      "        [ -3.3284,  -6.7832,  -5.6104],\n",
      "        [ -4.2825,  -2.9918,  -3.0187],\n",
      "        [ -0.7765,  -5.8579,  -1.3900],\n",
      "        [ -0.1474,  -6.7637,  -0.0690],\n",
      "        [ -1.5665,  -1.5476,  -3.9487],\n",
      "        [-30.9494,  -1.4184,  -5.9856],\n",
      "        [ -8.4707,  -3.4516,  -0.6950],\n",
      "        [ -0.1591,  -8.4773,  -9.4943],\n",
      "        [ -1.2619,  -8.8456,  -2.2075],\n",
      "        [-12.0580,  -5.1323,  -0.1489],\n",
      "        [ -0.7447,  -2.0286,  -0.1908],\n",
      "        [ -1.4702,  -1.8231,  -1.9911],\n",
      "        [ -1.2020,  -7.6068,  -1.4482],\n",
      "        [ -0.2710,  -1.4370,  -0.3663],\n",
      "        [ -0.6182,  -2.0518,  -0.1240],\n",
      "        [ -2.0925,  -5.3308,  -1.2050],\n",
      "        [ -0.2407,  -4.2471,  -4.6557],\n",
      "        [ -1.5930,  -1.4326,  -1.0387],\n",
      "        [-28.1611,  -1.6681,  -2.9349],\n",
      "        [ -1.9154,  -1.5121,  -0.1991],\n",
      "        [ -0.3629,  -1.4179,  -1.2125],\n",
      "        [ -0.1644,  -6.0255, -25.7708],\n",
      "        [ -7.0197,  -1.6933,  -2.5137],\n",
      "        [ -0.6936,  -1.8605,  -1.2084],\n",
      "        [ -5.1843,  -1.4973,  -5.3588],\n",
      "        [ -0.8381,  -3.0545, -25.7160],\n",
      "        [ -0.1407,  -2.2178,  -4.6207],\n",
      "        [ -1.5746,  -2.9813,  -2.6905],\n",
      "        [ -3.6318,  -1.6915,  -5.8989],\n",
      "        [ -1.5835,  -2.0219,  -0.7439],\n",
      "        [ -2.0625,  -1.4188,  -0.6403],\n",
      "        [ -0.6806,  -3.3120,  -0.0832],\n",
      "        [-12.3907,  -8.4847, -13.2737],\n",
      "        [ -8.7878,  -1.4679,  -7.4948],\n",
      "        [ -0.3867,  -1.8807,  -0.0641],\n",
      "        [ -0.1260,  -2.0460,  -2.4375],\n",
      "        [ -2.0343,  -4.8104,  -7.2463],\n",
      "        [ -0.1273,  -3.2056,  -3.0871],\n",
      "        [ -4.2750,  -2.9133,  -0.1158],\n",
      "        [ -0.1343,  -4.4250,  -1.6295],\n",
      "        [ -5.4838, -19.6464,  -0.0895],\n",
      "        [ -1.4378,  -8.6679,  -2.7796],\n",
      "        [ -3.3614,  -1.4542,  -6.1847],\n",
      "        [ -0.2237,  -2.0004,  -3.5453],\n",
      "        [ -2.4257,  -3.7166,  -2.9601],\n",
      "        [ -1.0922,  -6.5179,  -0.0921],\n",
      "        [-11.2468,  -1.4314, -15.4449],\n",
      "        [ -2.4105,  -3.3019,  -0.6416],\n",
      "        [ -4.2936,  -4.1946,  -0.0644],\n",
      "        [ -2.3948,  -5.6041,  -1.1818],\n",
      "        [ -3.8975,  -7.2760,  -1.4809],\n",
      "        [ -1.5199,  -4.5214,  -0.5370],\n",
      "        [-10.9015,  -1.6476,  -0.9206],\n",
      "        [ -3.5077,  -6.1179,  -3.0483],\n",
      "        [ -0.1573,  -3.7737, -16.1843],\n",
      "        [ -0.3470,  -9.6797,  -0.3426],\n",
      "        [ -0.2060,  -2.4624, -19.9228],\n",
      "        [ -1.9347,  -1.5639,  -0.0776],\n",
      "        [ -1.3063,  -6.6802,  -4.2654],\n",
      "        [ -6.5044,  -1.9632, -15.3048],\n",
      "        [-11.5555,  -1.8148,  -0.0742],\n",
      "        [ -2.7662,  -1.4423,  -5.7486],\n",
      "        [ -0.1502,  -2.8544,  -2.9742],\n",
      "        [ -1.3230,  -2.7503,  -0.6375],\n",
      "        [ -2.9751,  -1.6619,  -6.3297],\n",
      "        [ -1.7171,  -2.7559,  -9.4569],\n",
      "        [ -2.3944,  -6.3902, -23.4845],\n",
      "        [ -0.8192,  -8.0290,  -2.2712],\n",
      "        [ -6.5658,  -3.6777,  -0.0820],\n",
      "        [ -0.1324,  -2.1692,  -3.0642],\n",
      "        [ -3.0373,  -6.0685,  -4.6694],\n",
      "        [ -0.4096,  -1.4910,  -0.0940],\n",
      "        [ -0.2034,  -1.4423,  -0.8227]], grad_fn=<NegBackward>)\n",
      "tensor([[[-1.3169, -1.5082,  0.3772]],\n",
      "\n",
      "        [[ 0.6723, -0.9584,  1.7900]],\n",
      "\n",
      "        [[ 1.1555,  1.6555, -0.7698]],\n",
      "\n",
      "        [[ 1.2994, -0.4062, -0.4025]],\n",
      "\n",
      "        [[-0.3435, -0.8984,  1.2548]],\n",
      "\n",
      "        [[ 0.2072,  1.6530,  0.5490]],\n",
      "\n",
      "        [[-0.5707,  0.1101,  1.7279]],\n",
      "\n",
      "        [[-3.0831,  0.3331, -0.8150]],\n",
      "\n",
      "        [[-1.5455, -0.5053,  1.0485]],\n",
      "\n",
      "        [[ 0.2277, -1.2159, -1.1830]],\n",
      "\n",
      "        [[-0.4931,  1.8916, -0.2554]],\n",
      "\n",
      "        [[ 2.1167, -0.7946,  0.7581]],\n",
      "\n",
      "        [[ 0.5766,  0.7694,  0.3843]],\n",
      "\n",
      "        [[-0.5471, -0.0494, -0.2115]],\n",
      "\n",
      "        [[ 0.7213, -1.1182,  1.2692]],\n",
      "\n",
      "        [[ 0.3424,  0.3982,  0.2725]],\n",
      "\n",
      "        [[-0.2828, -0.1416,  0.4485]],\n",
      "\n",
      "        [[ 0.9320,  1.4602, -0.0268]],\n",
      "\n",
      "        [[-0.0734, -0.6530,  1.8271]],\n",
      "\n",
      "        [[ 0.8217,  0.2477,  0.0199]],\n",
      "\n",
      "        [[-2.9347,  0.6070, -0.3883]],\n",
      "\n",
      "        [[-0.6501,  0.4955,  0.3777]],\n",
      "\n",
      "        [[-0.1589,  0.3121, -0.0288]],\n",
      "\n",
      "        [[ 0.0088, -0.9212, -2.3373]],\n",
      "\n",
      "        [[-1.3936,  0.6212,  1.4936]],\n",
      "\n",
      "        [[-0.3128, -0.0660,  1.2076]],\n",
      "\n",
      "        [[ 1.4208,  0.1553, -0.7386]],\n",
      "\n",
      "        [[ 0.6096, -0.4205, -2.3342]],\n",
      "\n",
      "        [[ 0.1929, -0.1983,  1.8224]],\n",
      "\n",
      "        [[ 0.8173, -0.4038, -0.3458]],\n",
      "\n",
      "        [[-0.9588,  0.6202, -0.8047]],\n",
      "\n",
      "        [[ 0.8194,  0.7669,  0.1139]],\n",
      "\n",
      "        [[-0.6812,  0.2993,  0.1516]],\n",
      "\n",
      "        [[ 0.5524, -0.4765,  0.5098]],\n",
      "\n",
      "        [[-1.8997, -1.2167, -1.5085]],\n",
      "\n",
      "        [[ 1.8215,  0.4475,  2.1638]],\n",
      "\n",
      "        [[-0.1726, -0.0747,  0.5827]],\n",
      "\n",
      "        [[ 0.1127, -0.1395, -0.2996]],\n",
      "\n",
      "        [[-0.6753, -0.7453, -0.9574]],\n",
      "\n",
      "        [[ 0.0995, -0.4538, -0.4139]],\n",
      "\n",
      "        [[ 1.2984,  1.0242,  0.7214]],\n",
      "\n",
      "        [[ 0.0687,  1.3193, -0.1325]],\n",
      "\n",
      "        [[-1.2141, -2.1469,  0.4976]],\n",
      "\n",
      "        [[ 0.7836, -1.2364, -0.3615]],\n",
      "\n",
      "        [[ 1.1609,  0.4283, -0.8384]],\n",
      "\n",
      "        [[ 0.3031, -0.1226,  1.6672]],\n",
      "\n",
      "        [[-0.7533, -0.5572, -0.3926]],\n",
      "\n",
      "        [[-0.4453, -0.9857,  0.4931]],\n",
      "\n",
      "        [[-1.8031,  0.3856, -1.6744]],\n",
      "\n",
      "        [[-0.7504,  1.1106,  0.1511]],\n",
      "\n",
      "        [[-1.0564,  1.2802,  0.6015]],\n",
      "\n",
      "        [[ 0.9920, -0.8632, -0.0205]],\n",
      "\n",
      "        [[-0.9990, -1.0793,  1.2772]],\n",
      "\n",
      "        [[-0.5594, -0.6990,  0.1928]],\n",
      "\n",
      "        [[-1.7729,  0.5950,  0.0556]],\n",
      "\n",
      "        [[-0.9394,  1.5698, -0.4075]],\n",
      "\n",
      "        [[ 0.2250, -0.5681, -1.7281]],\n",
      "\n",
      "        [[ 0.3939, -1.3414,  0.2852]],\n",
      "\n",
      "        [[ 0.2859, -0.2720, -1.9829]],\n",
      "\n",
      "        [[ 0.8988,  0.5388,  0.5225]],\n",
      "\n",
      "        [[ 0.7496, -1.0063,  1.7733]],\n",
      "\n",
      "        [[ 1.5805, -0.1083, -1.6640]],\n",
      "\n",
      "        [[-1.8296,  0.6819,  0.6483]],\n",
      "\n",
      "        [[ 1.0605,  0.2277, -0.7866]],\n",
      "\n",
      "        [[ 0.0320, -0.3739, -0.3950]],\n",
      "\n",
      "        [[ 0.7540, -0.3483,  0.1527]],\n",
      "\n",
      "        [[-0.8523,  0.0329,  2.0351]],\n",
      "\n",
      "        [[-0.6060,  0.9860, -1.1795]],\n",
      "\n",
      "        [[-0.7473,  1.6056, -2.2041]],\n",
      "\n",
      "        [[-0.3585, -1.1664, -0.2678]],\n",
      "\n",
      "        [[-1.3429,  1.1861,  0.5125]],\n",
      "\n",
      "        [[ 0.0753, -0.1823,  1.5900]],\n",
      "\n",
      "        [[-0.8628, -0.9270, -0.6491]],\n",
      "\n",
      "        [[-0.1853,  0.1618,  0.4899]],\n",
      "\n",
      "        [[-0.0386,  0.4086,  0.0870]]]) tensor([[[-1.3169, -1.5082,  0.3772]],\n",
      "\n",
      "        [[ 0.6723, -0.9584,  1.7900]],\n",
      "\n",
      "        [[ 1.1555,  1.6555, -0.7698]],\n",
      "\n",
      "        [[ 1.2994, -0.4062, -0.4025]],\n",
      "\n",
      "        [[-0.3435, -0.8984,  1.2548]],\n",
      "\n",
      "        [[ 0.2072,  1.6530,  0.5490]],\n",
      "\n",
      "        [[-0.5707,  0.1101,  1.7279]],\n",
      "\n",
      "        [[-3.0831,  0.3331, -0.8150]],\n",
      "\n",
      "        [[-1.5455, -0.5053,  1.0485]],\n",
      "\n",
      "        [[ 0.2277, -1.2159, -1.1830]],\n",
      "\n",
      "        [[-0.4931,  1.8916, -0.2554]],\n",
      "\n",
      "        [[ 2.1167, -0.7946,  0.7581]],\n",
      "\n",
      "        [[ 0.5766,  0.7694,  0.3843]],\n",
      "\n",
      "        [[-0.5471, -0.0494, -0.2115]],\n",
      "\n",
      "        [[ 0.7213, -1.1182,  1.2692]],\n",
      "\n",
      "        [[ 0.3424,  0.3982,  0.2725]],\n",
      "\n",
      "        [[-0.2828, -0.1416,  0.4485]],\n",
      "\n",
      "        [[ 0.9320,  1.4602, -0.0268]],\n",
      "\n",
      "        [[-0.0734, -0.6530,  1.8271]],\n",
      "\n",
      "        [[ 0.8217,  0.2477,  0.0199]],\n",
      "\n",
      "        [[-2.9347,  0.6070, -0.3883]],\n",
      "\n",
      "        [[-0.6501,  0.4955,  0.3777]],\n",
      "\n",
      "        [[-0.1589,  0.3121, -0.0288]],\n",
      "\n",
      "        [[ 0.0088, -0.9212, -2.3373]],\n",
      "\n",
      "        [[-1.3936,  0.6212,  1.4936]],\n",
      "\n",
      "        [[-0.3128, -0.0660,  1.2076]],\n",
      "\n",
      "        [[ 1.4208,  0.1553, -0.7386]],\n",
      "\n",
      "        [[ 0.6096, -0.4205, -2.3342]],\n",
      "\n",
      "        [[ 0.1929, -0.1983,  1.8224]],\n",
      "\n",
      "        [[ 0.8173, -0.4038, -0.3458]],\n",
      "\n",
      "        [[-0.9588,  0.6202, -0.8047]],\n",
      "\n",
      "        [[ 0.8194,  0.7669,  0.1139]],\n",
      "\n",
      "        [[-0.6812,  0.2993,  0.1516]],\n",
      "\n",
      "        [[ 0.5524, -0.4765,  0.5098]],\n",
      "\n",
      "        [[-1.8997, -1.2167, -1.5085]],\n",
      "\n",
      "        [[ 1.8215,  0.4475,  2.1638]],\n",
      "\n",
      "        [[-0.1726, -0.0747,  0.5827]],\n",
      "\n",
      "        [[ 0.1127, -0.1395, -0.2996]],\n",
      "\n",
      "        [[-0.6753, -0.7453, -0.9574]],\n",
      "\n",
      "        [[ 0.0995, -0.4538, -0.4139]],\n",
      "\n",
      "        [[ 1.2984,  1.0242,  0.7214]],\n",
      "\n",
      "        [[ 0.0687,  1.3193, -0.1325]],\n",
      "\n",
      "        [[-1.2141, -2.1469,  0.4976]],\n",
      "\n",
      "        [[ 0.7836, -1.2364, -0.3615]],\n",
      "\n",
      "        [[ 1.1609,  0.4283, -0.8384]],\n",
      "\n",
      "        [[ 0.3031, -0.1226,  1.6672]],\n",
      "\n",
      "        [[-0.7533, -0.5572, -0.3926]],\n",
      "\n",
      "        [[-0.4453, -0.9857,  0.4931]],\n",
      "\n",
      "        [[-1.8031,  0.3856, -1.6744]],\n",
      "\n",
      "        [[-0.7504,  1.1106,  0.1511]],\n",
      "\n",
      "        [[-1.0564,  1.2802,  0.6015]],\n",
      "\n",
      "        [[ 0.9920, -0.8632, -0.0205]],\n",
      "\n",
      "        [[-0.9990, -1.0793,  1.2772]],\n",
      "\n",
      "        [[-0.5594, -0.6990,  0.1928]],\n",
      "\n",
      "        [[-1.7729,  0.5950,  0.0556]],\n",
      "\n",
      "        [[-0.9394,  1.5698, -0.4075]],\n",
      "\n",
      "        [[ 0.2250, -0.5681, -1.7281]],\n",
      "\n",
      "        [[ 0.3939, -1.3414,  0.2852]],\n",
      "\n",
      "        [[ 0.2859, -0.2720, -1.9829]],\n",
      "\n",
      "        [[ 0.8988,  0.5388,  0.5225]],\n",
      "\n",
      "        [[ 0.7496, -1.0063,  1.7733]],\n",
      "\n",
      "        [[ 1.5805, -0.1083, -1.6640]],\n",
      "\n",
      "        [[-1.8296,  0.6819,  0.6483]],\n",
      "\n",
      "        [[ 1.0605,  0.2277, -0.7866]],\n",
      "\n",
      "        [[ 0.0320, -0.3739, -0.3950]],\n",
      "\n",
      "        [[ 0.7540, -0.3483,  0.1527]],\n",
      "\n",
      "        [[-0.8523,  0.0329,  2.0351]],\n",
      "\n",
      "        [[-0.6060,  0.9860, -1.1795]],\n",
      "\n",
      "        [[-0.7473,  1.6056, -2.2041]],\n",
      "\n",
      "        [[-0.3585, -1.1664, -0.2678]],\n",
      "\n",
      "        [[-1.3429,  1.1861,  0.5125]],\n",
      "\n",
      "        [[ 0.0753, -0.1823,  1.5900]],\n",
      "\n",
      "        [[-0.8628, -0.9270, -0.6491]],\n",
      "\n",
      "        [[-0.1853,  0.1618,  0.4899]],\n",
      "\n",
      "        [[-0.0386,  0.4086,  0.0870]]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3, 75)\n",
    "b = torch.randn(3, 75)\n",
    "dim = 3\n",
    "\n",
    "a = torch.reshape(a, [-1, 1, dim]) # \n",
    "b = torch.reshape(a, [-1, 1, dim])\n",
    "\n",
    "aslist = list(c.shape)\n",
    "c = torch.reshape(c, [-1, 1, aslist[1], aslist[0]])\n",
    "def conv(attr_hs, attr_as, attr_vs, dim, feature_map_size=2, kernel_size=[2, 4], activation=nn.Tanh, layer_num=2):\n",
    "    # print(\"feature map size\", feature_map_size)\n",
    "    # print(\"kernel size\", kernel_size)\n",
    "    # print(\"layer_num\", layer_num)\n",
    "\n",
    "    class Conv(nn.Module):\n",
    "        def __init__(self, sizes):\n",
    "            super(Conv, self).__init__()\n",
    "            self.norm_channels = sizes[3]\n",
    "\n",
    "            self.in_channels = sizes[1]\n",
    "            self.out_channels = sizes[2]\n",
    "\n",
    "            self.con = nn.Conv2d(self.in_channels, self.out_channels, kernel_size=[2, 4])\n",
    "            self.con_consequent = nn.Conv2d(self.in_channels + 1, self.out_channels, kernel_size=[2, 4])\n",
    "            self.nrm = nn.BatchNorm2d(self.norm_channels)\n",
    "\n",
    "            self.activ_func_conv = activation()\n",
    "\n",
    "        def forward(self, input, conv_times, pad=(2, 1, 1, 0)):\n",
    "\n",
    "            sizes = list(input.shape)\n",
    "\n",
    "            input = torch.reshape(input, [-1, sizes[3], sizes[2], 1])\n",
    "            res = self.nrm(input)\n",
    "            res = torch.reshape(res, [-1, 1, sizes[2], sizes[3]])\n",
    "\n",
    "            padded = nn.functional.pad(res, pad)\n",
    "            res = self.con(padded)\n",
    "            res = self.activ_func_conv(res)\n",
    "\n",
    "            for i in range(conv_times-1):\n",
    "                padded = nn.functional.pad(res, pad)\n",
    "                res = self.con_consequent(padded)\n",
    "                res = self.activ_func_conv(res)\n",
    "\n",
    "            return res\n",
    "\n",
    "    attr_as = torch.reshape(attr_as, [-1, 1, dim])\n",
    "    attr_vs = torch.reshape(attr_vs, [-1, 1, dim])\n",
    "\n",
    "    input_avs = torch.cat([attr_as, attr_vs], 1)\n",
    "    input_shape = list(input_avs.shape)\n",
    "    input_layer = torch.reshape(input_avs, [-1, 1, input_shape[1], input_shape[0]])\n",
    "\n",
    "    c = Conv(list(input_layer.shape))\n",
    "    _conv = c.forward(input_layer, layer_num)\n",
    "\n",
    "    _conv = nn.functional.normalize(_conv, dim=1, p=2)\n",
    "    _shape = list(_conv.shape)\n",
    "    _flat = torch.reshape(_conv, [-1, _shape[3] * _shape[2] * _shape[1]])\n",
    "    # print(\"_flat\", _flat.shape)\n",
    "\n",
    "    class FlatProcessing(nn.Module):\n",
    "        def __init__(self, in_, out_, activation_):\n",
    "            super(FlatProcessing, self).__init__()\n",
    "            self.pipeline = nn.Sequential(\n",
    "                nn.Linear(in_, out_),\n",
    "                activation_()\n",
    "            )\n",
    "\n",
    "        def forward(self, arg):\n",
    "            return self.pipeline(arg)\n",
    "    denser = FlatProcessing(_flat.shape[1], dim, activation_=activation)\n",
    "    dense = denser.forward(_flat)\n",
    "    dense = nn.functional.normalize(dense, dim=1, p=2)\n",
    "    # print(\"dense\", dense.shape)\n",
    "    score = -torch.sum(torch.square(attr_hs - dense), 1)\n",
    "    return score\n",
    "print(conv(a,b,a,3))\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
